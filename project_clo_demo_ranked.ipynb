{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "poolSize = 5000\n",
    "\n",
    "senior_perc_contr = 0.5\n",
    "senior_ann_int = 0.05\n",
    "\n",
    "subordinate_perc_contr = 0.3\n",
    "subordinate_ann_int = 0.1\n",
    "\n",
    "equity_perc_contr = 0.1\n",
    "\n",
    "year = 2014\n",
    "term = 36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgbModel = xgb.Booster({'nthread': 4})  # init model\n",
    "xgbModel.load_model('xgb_best_model')  # load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "kerasModel = keras.models.load_model('keras_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_good_loan_ids = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_results_df = pd.read_csv('all_accept_xgb_df.csv') \n",
    "\n",
    "for i in range(len(xgb_results_df)):\n",
    "    if xgb_results_df.loc[i, \"predicted_val\"] == 1:\n",
    "        predicted_good_loan_ids.add(xgb_results_df.loc[i, \"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_results_df = pd.read_csv('all_accept_keras_df.csv') \n",
    "\n",
    "for i in range(len(keras_results_df)):\n",
    "    if keras_results_df.loc[i, \"predicted_val\"] == 1:\n",
    "        predicted_good_loan_ids.add(keras_results_df.loc[i, \"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kmanda/opt/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3063: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# all accepted loans from lendingclub\n",
    "all_accept_df = pd.read_csv('./archive/accepted_2007_to_2018q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_df = all_accept_df[all_accept_df['id'].isin(predicted_good_loan_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop invalid loan_status to 'Unknown'\n",
    "\n",
    "all_accept_df.loc[pd.isnull(all_accept_df['loan_status']),'loan_status'] = 'Unknown'\n",
    "\n",
    "all_accept_df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loan_status = all_accept_df['loan_status']\n",
    "\n",
    "loan_status[(loan_status=='Fully Paid') | (loan_status=='Current') |\n",
    "            (loan_status=='Does not meet the credit policy. Status:Fully Paid') |\n",
    "            (loan_status=='In Grace Period')] = 1\n",
    "\n",
    "loan_status[loan_status != 1] = 0\n",
    "\n",
    "all_accept_df['loan_status'] = pd.to_numeric(loan_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to numeric\n",
    "\n",
    "all_accept_df['term'] = pd.to_numeric(all_accept_df['term'].apply(lambda x: re.findall(r'\\d+', str(x))).str[0])\n",
    "all_accept_df['deferral_term'] = pd.to_numeric(all_accept_df['deferral_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter dataframe by year and term months \n",
    "# so as to create pools of poolSize\n",
    "\n",
    "all_accept_df = all_accept_df[pd.DatetimeIndex(all_accept_df['issue_d']).year == year]\n",
    "all_accept_df = all_accept_df[all_accept_df['term'] == term]\n",
    "\n",
    "sampleSize = int(all_accept_df.shape[0] / poolSize) * poolSize\n",
    "\n",
    "all_accept_df = all_accept_df.sample(sampleSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertDateTimeToOrdinal(d):\n",
    "    if d is pd.NaT:\n",
    "        return 0\n",
    "    else:\n",
    "        return d.toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to datetime (toordinal)\n",
    "\n",
    "dateCols = pd.Series(\n",
    "    ['issue_d',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'debt_settlement_flag_date',\n",
    "    'settlement_date',\n",
    "    'hardship_start_date',\n",
    "    'hardship_end_date',\n",
    "    'payment_plan_start_date',\n",
    "    'sec_app_earliest_cr_line'])\n",
    "\n",
    "for col in dateCols:    \n",
    "    all_accept_df[col] = pd.to_datetime(all_accept_df[col]).apply(ConvertDateTimeToOrdinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns to be ignore for now\n",
    "\n",
    "all_accept_df = all_accept_df.drop([\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'emp_length',\n",
    "    'home_ownership',\n",
    "    'url',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'initial_list_status',\n",
    "    'verification_status_joint',  \n",
    "    'hardship_type',\n",
    "    'hardship_reason',\n",
    "    'disbursement_method'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify\n",
    "\n",
    "colsToBeDummified = pd.Series(\n",
    "    ['grade',\n",
    "    'sub_grade',\n",
    "    'verification_status',\n",
    "    'purpose',\n",
    "    'pymnt_plan',\n",
    "    'application_type',\n",
    "    'hardship_flag',\n",
    "    'hardship_status',\n",
    "    'hardship_loan_status',\n",
    "    'debt_settlement_flag',\n",
    "    'settlement_status'])\n",
    "\n",
    "for col in colsToBeDummified:    \n",
    "    all_accept_df = all_accept_df.join(pd.get_dummies(all_accept_df[col], drop_first=True, prefix=col))\n",
    "    all_accept_df = all_accept_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle na\n",
    "\n",
    "all_accept_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure all columns are numeric\n",
    "\n",
    "for col in all_accept_df.columns:\n",
    "    all_accept_df[col] = pd.to_numeric(all_accept_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define function to evaluate tranche returns for pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluatePools(pools):\n",
    "    total_loan_amnts = []\n",
    "    avg_int_rate = []\n",
    "    avg_dti = []\n",
    "    avg_fico_range_low = []\n",
    "    avg_fico_range_high = []\n",
    "    total_pymnts = []\n",
    "    total_rec_prncp = []\n",
    "    total_rec_int = []\n",
    "\n",
    "    senior_init_pymt = []\n",
    "    senior_total_pymt = []\n",
    "    senior_int = []\n",
    "\n",
    "    subordinate_init_pymt = []\n",
    "    subordinate_total_pymt = []\n",
    "    subordinate_int = []\n",
    "\n",
    "    equity_init_pymt = []\n",
    "    equity_total_pymt = []\n",
    "    equity_int = []\n",
    "\n",
    "    total_calc_pymnts = []\n",
    "    \n",
    "    for pool in pools:\n",
    "        total_loan_amnt = np.sum(pool['loan_amnt'])\n",
    "        total_pymt = np.sum(pool['total_pymnt'])\n",
    "        \n",
    "        total_loan_amnts.append(total_loan_amnt)\n",
    "        avg_int_rate.append(np.mean(pool['int_rate']))\n",
    "        avg_dti.append(np.mean(pool['dti']))\n",
    "        avg_fico_range_low.append(np.mean(pool['fico_range_low']))\n",
    "        avg_fico_range_high.append(np.mean(pool['fico_range_high']))\n",
    "        total_pymnts.append(total_pymt)\n",
    "        total_rec_prncp.append(np.sum(pool['total_rec_prncp']))\n",
    "        total_rec_int.append(np.sum(pool['total_rec_int']))\n",
    "\n",
    "        #senior tranche\n",
    "        init_pymt = senior_perc_contr*total_loan_amnt\n",
    "        senior_init_pymt.append(init_pymt)\n",
    "\n",
    "        total_sen_pymt = np.pmt(senior_ann_int/12, term, -senior_perc_contr*total_loan_amnt) * term\n",
    "        senior_total_pymt.append(total_sen_pymt)\n",
    "\n",
    "        if total_sen_pymt < total_pymt:\n",
    "            senior_int.append(senior_ann_int * 100)\n",
    "        else:\n",
    "            int_approx = np.rate(term, total_pymt / term, -init_pymt, 0) * 12 * 100\n",
    "            senior_int.append(int_approx)\n",
    "\n",
    "        #subordinate tranche\n",
    "        init_pymt = subordinate_perc_contr*total_loan_amnt\n",
    "        subordinate_init_pymt.append(init_pymt)\n",
    "\n",
    "        total_subordinate_pymt = np.pmt(subordinate_ann_int/12, term, -subordinate_perc_contr*total_loan_amnt) * term\n",
    "        subordinate_total_pymt.append(total_subordinate_pymt)\n",
    "\n",
    "        if (total_sen_pymt + total_subordinate_pymt) < total_pymt:\n",
    "            subordinate_int.append(subordinate_ann_int * 100)\n",
    "        else:\n",
    "            int_approx = np.rate(term, (total_pymt - total_sen_pymt) / term, -init_pymt, 0) * 12 * 100\n",
    "            subordinate_int.append(int_approx)\n",
    "\n",
    "        #equity tranche\n",
    "        init_pymt = equity_perc_contr*total_loan_amnt\n",
    "        equity_init_pymt.append(init_pymt)\n",
    "\n",
    "        total_equity_pymt = total_pymt - total_sen_pymt - total_subordinate_pymt\n",
    "        equity_total_pymt.append(total_equity_pymt)\n",
    "\n",
    "        int_approx = np.rate(36, 0, -init_pymt, total_equity_pymt) * 12 * 100\n",
    "        equity_int.append(int_approx)\n",
    "\n",
    "        #total calculated payments\n",
    "        total_calc_pymnts.append(total_sen_pymt+total_subordinate_pymt+total_equity_pymt)\n",
    "    \n",
    "    #create results data frame\n",
    "    list_of_tuples = list(zip(total_loan_amnts, avg_int_rate, avg_dti, avg_fico_range_low, avg_fico_range_high, total_pymnts, total_rec_prncp, total_rec_int, senior_init_pymt, senior_total_pymt, senior_int, subordinate_init_pymt, subordinate_total_pymt, subordinate_int, equity_init_pymt, equity_total_pymt, equity_int, total_calc_pymnts))\n",
    "\n",
    "    pool_results_df = pd.DataFrame(list_of_tuples,\n",
    "                                  columns = ['total_loan_amnts', 'avg_int_rate', 'avg_dti', 'avg_fico_range_low', 'avg_fico_range_high', 'total_pymnts', 'total_rec_prncp', 'total_rec_int', 'senior_init_pymt', 'senior_total_pymt', 'senior_int', 'subordinate_init_pymt', 'subordinate_total_pymt', 'subordinate_int', 'equity_init_pymt', 'equity_total_pymt', 'equity_int', 'total_calc_pymnts'])\n",
    "\n",
    "    return(pool_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate performance of randomly created pools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "pools = []\n",
    "\n",
    "while i < all_accept_df.shape[0]:\n",
    "    pools.append(pd.DataFrame(all_accept_df[i:i+poolSize]))\n",
    "    i = i + poolSize\n",
    "    \n",
    "pool_results_df = evaluatePools(pools)\n",
    "\n",
    "print(pool_results_df.shape)\n",
    "pool_results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt = pool_results_df.plot(y=[\"senior_int\", \"subordinate_int\", \"equity_int\"], kind=\"bar\", figsize=(14, 12))\n",
    "plt.legend([\"Senior tranche interest rate\", \"Subordinate tranche interest rate\", \"Equity tranche interest rate\"])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
