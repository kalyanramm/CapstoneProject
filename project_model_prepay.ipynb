{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# all accepted loans from lendingclub\n",
    "all_accept_df = pd.read_csv('./archive/accepted_2007_to_2018q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to numeric\n",
    "\n",
    "all_accept_df['term'] = pd.to_numeric(all_accept_df['term'].apply(lambda x: re.findall(r'\\d+', str(x))).str[0])\n",
    "\n",
    "# convert columns to date\n",
    "\n",
    "all_accept_df['issue_d'] = pd.to_datetime(all_accept_df['issue_d'])\n",
    "all_accept_df['last_pymnt_d'] = pd.to_datetime(all_accept_df['last_pymnt_d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AddMonthsToDate(dates, months):\n",
    "    updatedDates = []\n",
    "    \n",
    "    for i in range(0, len(dates)):\n",
    "        toAddMnths = pd.to_numeric(months.iat[i]) - 3\n",
    "        updatedDates.append(dates.iat[i] + pd.DateOffset(months=toAddMnths))\n",
    "        \n",
    "    return updatedDates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2260668\n",
      "2260668\n"
     ]
    }
   ],
   "source": [
    "all_accept_df = all_accept_df.dropna(subset=['issue_d', 'term'])\n",
    "\n",
    "print(len(all_accept_df['issue_d']))\n",
    "\n",
    "updatedDates = AddMonthsToDate(all_accept_df['issue_d'], all_accept_df['term'])\n",
    "\n",
    "print(len(updatedDates))\n",
    "\n",
    "all_accept_df['loan_prepaid'] = (\n",
    "        ((all_accept_df['loan_status'] == 'Fully Paid') | (all_accept_df['loan_status'] == 'Does not meet the credit policy. Status:Fully Paid')) & \n",
    "            (all_accept_df['last_pymnt_d'] < updatedDates))\n",
    "\n",
    "\n",
    "all_accept_df = all_accept_df.drop('loan_status', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    1454758\n",
       "True      805910\n",
       "Name: loan_prepaid, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accept_df['loan_prepaid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertDateTimeToOrdinal(d):\n",
    "    if d is pd.NaT:\n",
    "        return 0\n",
    "    else:\n",
    "        return d.toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to datetime (toordinal)\n",
    "\n",
    "dateCols = pd.Series(\n",
    "    ['issue_d',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'debt_settlement_flag_date',\n",
    "    'settlement_date',\n",
    "    'hardship_start_date',\n",
    "    'hardship_end_date',\n",
    "    'payment_plan_start_date',\n",
    "    'sec_app_earliest_cr_line'])\n",
    "\n",
    "for col in dateCols:    \n",
    "    all_accept_df[col] = pd.to_datetime(all_accept_df[col]).apply(ConvertDateTimeToOrdinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns to be ignore for now\n",
    "\n",
    "all_accept_df = all_accept_df.drop([\n",
    "    'id',\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'emp_length',\n",
    "    'home_ownership',\n",
    "    'url',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'initial_list_status',\n",
    "    'verification_status_joint',  \n",
    "    'hardship_type',\n",
    "    'hardship_reason',\n",
    "    'disbursement_method'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to numeric\n",
    "\n",
    "all_accept_df['term'] = pd.to_numeric(all_accept_df['term'].apply(lambda x: re.findall(r'\\d+', str(x))).str[0])\n",
    "all_accept_df['deferral_term'] = pd.to_numeric(all_accept_df['deferral_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify\n",
    "\n",
    "colsToBeDummified = pd.Series(\n",
    "    ['grade',\n",
    "    'sub_grade',\n",
    "    'verification_status',\n",
    "    'purpose',\n",
    "    'pymnt_plan',\n",
    "    'application_type',\n",
    "    'hardship_flag',\n",
    "    'hardship_status',\n",
    "    'hardship_loan_status',\n",
    "    'debt_settlement_flag',\n",
    "    'settlement_status'])\n",
    "\n",
    "for col in colsToBeDummified:    \n",
    "    all_accept_df = all_accept_df.join(pd.get_dummies(all_accept_df[col], drop_first=True, prefix=col))\n",
    "    all_accept_df = all_accept_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle na\n",
    "\n",
    "all_accept_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_accept_train_df, all_accept_test_df, all_accept_train_target, all_accept_test_target = \\\n",
    "            train_test_split(all_accept_df, all_accept_df['loan_prepaid'], test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-9b912882cf0c>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_accept_train_df[col] = pd.to_numeric(all_accept_train_df[col])\n",
      "<ipython-input-15-9b912882cf0c>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_accept_test_df[col] = pd.to_numeric(all_accept_test_df[col])\n"
     ]
    }
   ],
   "source": [
    "# make sure all columns are numeric\n",
    "\n",
    "for col in all_accept_train_df.columns:\n",
    "    all_accept_train_df[col] = pd.to_numeric(all_accept_train_df[col])\n",
    "    all_accept_test_df[col] = pd.to_numeric(all_accept_test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1808534 entries, 1497595 to 1873441\n",
      "Columns: 192 entries, loan_amnt to settlement_status_COMPLETE\n",
      "dtypes: bool(1), float64(112), int64(12), uint8(67)\n",
      "memory usage: 1.8 GB\n"
     ]
    }
   ],
   "source": [
    "all_accept_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 452134 entries, 1532366 to 110876\n",
      "Columns: 192 entries, loan_amnt to settlement_status_COMPLETE\n",
      "dtypes: bool(1), float64(112), int64(12), uint8(67)\n",
      "memory usage: 460.5 MB\n"
     ]
    }
   ],
   "source": [
    "all_accept_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term',\n",
    "    'int_rate', 'grade_B', 'grade_C',\n",
    "    'grade_D', 'grade_E', 'grade_F', 'grade_G',\n",
    "    'sub_grade_A2', 'sub_grade_A3', 'sub_grade_A4', 'sub_grade_A5', \n",
    "    'sub_grade_B2', 'sub_grade_B3', 'sub_grade_B4', 'sub_grade_B5',\n",
    "    'sub_grade_C1', 'sub_grade_C2', 'sub_grade_C3', 'sub_grade_C4',\n",
    "    'sub_grade_C5', 'sub_grade_D1', 'sub_grade_D2', 'sub_grade_D3',\n",
    "    'sub_grade_D4', 'sub_grade_D5', 'sub_grade_E1', 'sub_grade_E2',\n",
    "    'sub_grade_E3', 'sub_grade_E4', 'sub_grade_E5', 'sub_grade_F1',\n",
    "    'sub_grade_F2', 'sub_grade_F3', 'sub_grade_F4', 'sub_grade_F5',\n",
    "    'sub_grade_G1', 'sub_grade_G2', 'sub_grade_G3', 'sub_grade_G4',\n",
    "    'sub_grade_G5', 'sub_grade_B1','purpose_credit_card', 'purpose_debt_consolidation',\n",
    "    'purpose_home_improvement', 'purpose_medical', 'purpose_other', \n",
    "    'purpose_small_business', 'annual_inc',\n",
    "    'issue_d', 'dti', 'delinq_2yrs', 'fico_range_low', 'fico_range_high',\n",
    "    'open_acc', 'total_acc', 'total_pymnt',\n",
    "    'total_pymnt_inv', 'last_pymnt_d', 'last_pymnt_amnt',\n",
    "    'annual_inc_joint', 'dti_joint', 'acc_now_delinq', 'tot_coll_amt', 'tot_cur_bal',\n",
    "    'tot_hi_cred_lim', 'total_bal_ex_mort', 'total_bc_limit', 'total_il_high_credit_limit',\n",
    "    'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = all_accept_train_df.columns.isin(features)\n",
    "\n",
    "kBestColumns = all_accept_train_df.columns[mask]\n",
    "otherColumnsToBeCombined = all_accept_train_df.columns[~mask]\n",
    "\n",
    "len(kBestColumns) + len(otherColumnsToBeCombined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - PCA on non-kBest columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - Modify train data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1808534, 21)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accept_train_otherColsDf = pd.DataFrame(all_accept_train_df[otherColumnsToBeCombined])\n",
    "\n",
    "data_rescaled = scaler.fit_transform(all_accept_train_otherColsDf)\n",
    "\n",
    "pca.fit(data_rescaled)\n",
    "\n",
    "reduced = pca.transform(data_rescaled)\n",
    "reduced = pd.DataFrame(reduced)\n",
    "\n",
    "reduced.fillna(0, inplace=True)\n",
    "\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1808534, 75)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(all_accept_train_df[kBestColumns]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1808534, 96)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kBestColsDf = pd.DataFrame(all_accept_train_df[kBestColumns])\n",
    "\n",
    "all_accept_train_df = \\\n",
    "    pd.concat([kBestColsDf, reduced.reindex(kBestColsDf.index)], axis=1)\n",
    "\n",
    "all_accept_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - Modify test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452134, 21)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accept_test_otherColsDf = pd.DataFrame(all_accept_test_df[otherColumnsToBeCombined])\n",
    "\n",
    "reduced = pca.transform(all_accept_test_otherColsDf)\n",
    "reduced = pd.DataFrame(reduced)\n",
    "\n",
    "reduced.fillna(0, inplace=True)\n",
    "\n",
    "reduced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(452134, 96)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kBestColsDf = pd.DataFrame(all_accept_test_df[kBestColumns])\n",
    "\n",
    "all_accept_test_df = \\\n",
    "    pd.concat([kBestColsDf, reduced.reindex(kBestColsDf.index)], axis=1)\n",
    "\n",
    "all_accept_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrink data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_range_train = range(1, all_accept_train_df.shape[0])\n",
    "#n_range_train = range(1, 20000)\n",
    "\n",
    "all_accept_train_df_r = pd.DataFrame(all_accept_train_df.iloc[n_range_train])\n",
    "all_accept_train_target_r = all_accept_train_target.iloc[n_range_train] \n",
    "\n",
    "all_accept_train_df_r.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_range_test = range(1, all_accept_test_df.shape[0])\n",
    "#n_range_test = range(1, 2000)\n",
    "\n",
    "all_accept_test_df_r = pd.DataFrame(all_accept_test_df.iloc[n_range_test])\n",
    "all_accept_test_target_r = all_accept_test_target.iloc[n_range_test] \n",
    "\n",
    "all_accept_test_df_r.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "n_jobs = 6\n",
    "#n_jobs = 2\n",
    "cv = 5\n",
    "accuracy = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "tree_model = tree.DecisionTreeClassifier()\n",
    "\n",
    "grid_para_tree = [{\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"min_samples_leaf\": range(1, 10),\n",
    "    \"min_samples_split\": np.linspace(start=2, stop=30, num=15, dtype=int)\n",
    "}]\n",
    "\n",
    "tree_model.set_params(random_state=random_state)\n",
    "\n",
    "grid_search_tree = model_selection.GridSearchCV(tree_model, grid_para_tree,\n",
    "                                                cv=cv, scoring=accuracy,\n",
    "                                                n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 13h 12min 50s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=100), n_jobs=6,\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'min_samples_leaf': range(1, 10),\n",
       "                          'min_samples_split': array([ 2,  4,  6,  8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30])}],\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid_search_tree.fit(all_accept_train_df_r, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9941007435308065"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.score(all_accept_train_df_r, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9879172721301033"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_tree.score(all_accept_test_df_r, all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1157910,    4863],\n",
       "       [   5806,  639954]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(grid_search_tree.predict(all_accept_train_df_r), all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[288190,   2613],\n",
       "       [  2850, 158480]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(grid_search_tree.predict(all_accept_test_df_r), all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgb_c = xgb.XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=n_jobs,\n",
    "    seed=random_state\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': range (5, 7, 10),\n",
    "    'n_estimators': range(100, 150, 200),\n",
    "    'learning_rate': [0.25, 0.2, 0.1]\n",
    "}\n",
    "\n",
    "grid_search_xgb = model_selection.GridSearchCV(\n",
    "    estimator=xgb_c,\n",
    "    param_grid=parameters,\n",
    "    scoring = accuracy,\n",
    "    n_jobs = n_jobs,\n",
    "    cv = cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23:49:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Wall time: 47min 26s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constraints=None,\n",
       "                                     n_estimators=100, n_jobs=None, nthread=6,\n",
       "                                     num_parallel_tree=None, random_state=None,\n",
       "                                     reg_alpha=None, reg_lambda=None,\n",
       "                                     scale_pos_weight=None, seed=100,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=None, verbosity=None),\n",
       "             n_jobs=6,\n",
       "             param_grid={'learning_rate': [0.25, 0.2, 0.1],\n",
       "                         'max_depth': range(5, 7, 10),\n",
       "                         'n_estimators': range(100, 150, 200)},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time grid_search_xgb.fit(all_accept_train_df_r, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935251388832828"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.score(all_accept_train_df_r, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9929202248011094"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_xgb.score(all_accept_test_df_r, all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1158122,    6116],\n",
       "       [   5594,  638701]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(grid_search_xgb.predict(all_accept_train_df_r), all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[289465,   1626],\n",
       "       [  1575, 159467]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(grid_search_xgb.predict(all_accept_test_df_r), all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import sklearn\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import initializers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "all_accept_train_df_r_scaled = scaler.fit_transform(all_accept_train_df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\initializers\\initializers_v1.py:67: calling TruncatedNormal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Time elapsed:  39688.28752946854\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tf.set_random_seed(random_state)\n",
    "\n",
    "num_observations = all_accept_train_df_r_scaled.shape[0]\n",
    "num_features     = all_accept_train_df_r_scaled.shape[1]\n",
    "\n",
    "kernel_initializer = initializers.TruncatedNormal(mean=0.0,stddev=0.1)\n",
    "bias_initializer   = initializers.Constant(0.1)\n",
    "    \n",
    "model.add(Dense(num_features*2, input_dim=num_features, input_shape=(num_features,),\n",
    "                activation=tf.nn.relu, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_features, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(num_features/2, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1, activation=tf.nn.sigmoid))\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "model.compile(loss=bce, optimizer=sgd, metrics=[accuracy])\n",
    "\n",
    "model.fit(all_accept_train_df_r_scaled, all_accept_train_target_r.values, epochs=1000, batch_size=100, verbose=0)\n",
    "\n",
    "print('Time elapsed: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.8895426721784375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1156501,    9711],\n",
       "       [   7215,  635106]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict_classes(all_accept_train_df_r_scaled)\n",
    "\n",
    "print ('Training Accuracy: ', np.mean(predict == np.argmax(all_accept_train_target_r, 0)))\n",
    "\n",
    "confusion_matrix(predict, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.8746838327864588\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[289053,   2311],\n",
       "       [  1987, 158782]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "all_accept_test_df_r_scaled = scaler.fit_transform(all_accept_test_df_r)\n",
    "\n",
    "predict = model.predict_classes(all_accept_test_df_r_scaled)\n",
    "print('Test Accuracy: ', np.mean(predict == np.argmax(all_accept_test_target_r, 0)))\n",
    "\n",
    "confusion_matrix(predict, all_accept_test_target_r)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
