{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime as dt\n",
    "\n",
    "from sklearn import model_selection\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 100\n",
    "n_jobs = 6\n",
    "#n_jobs = 2\n",
    "cv = 5\n",
    "accuracy = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (0,19,49,59,118,129,130,131,134,135,136,139,145,146,147) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# all accepted loans from lendingclub\n",
    "all_accept_df = pd.read_csv('./archive/accepted_2007_to_2018q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fully Paid', 'Current', 'Charged Off', 'In Grace Period',\n",
       "       'Late (31-120 days)', 'Late (16-30 days)', 'Default', 'Unknown',\n",
       "       'Does not meet the credit policy. Status:Fully Paid',\n",
       "       'Does not meet the credit policy. Status:Charged Off'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop invalid loan_status to 'Unknown'\n",
    "\n",
    "all_accept_df.loc[pd.isnull(all_accept_df['loan_status']),'loan_status'] = 'Unknown'\n",
    "\n",
    "all_accept_df.loan_status.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-e98628443b49>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  loan_status[(loan_status=='Fully Paid') | (loan_status=='Current') |\n",
      "<ipython-input-5-e98628443b49>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  loan_status[loan_status != 1] = 0\n"
     ]
    }
   ],
   "source": [
    "loan_status = all_accept_df['loan_status']\n",
    "\n",
    "loan_status[(loan_status=='Fully Paid') | (loan_status=='Current') |\n",
    "            (loan_status=='Does not meet the credit policy. Status:Fully Paid') |\n",
    "            (loan_status=='In Grace Period')] = 1\n",
    "\n",
    "loan_status[loan_status != 1] = 0\n",
    "\n",
    "all_accept_df['loan_status'] = pd.to_numeric(loan_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvertDateTimeToOrdinal(d):\n",
    "    if d is pd.NaT:\n",
    "        return 0\n",
    "    else:\n",
    "        return d.toordinal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter bad loan ids\n",
    "\n",
    "all_accept_df = all_accept_df[~all_accept_df['id'].str.contains(\"Total amount funded in policy code\", na=False)]\n",
    "all_accept_df = all_accept_df[~all_accept_df['id'].str.contains(\"Loans that do not meet the credit policy\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert columns to datetime (toordinal)\n",
    "\n",
    "dateCols = pd.Series(\n",
    "    ['issue_d',\n",
    "    'earliest_cr_line',\n",
    "    'last_pymnt_d',\n",
    "    'next_pymnt_d',\n",
    "    'last_credit_pull_d',\n",
    "    'debt_settlement_flag_date',\n",
    "    'settlement_date',\n",
    "    'hardship_start_date',\n",
    "    'hardship_end_date',\n",
    "    'payment_plan_start_date',\n",
    "    'sec_app_earliest_cr_line'])\n",
    "\n",
    "for col in dateCols:    \n",
    "    all_accept_df[col] = pd.to_datetime(all_accept_df[col]).apply(ConvertDateTimeToOrdinal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns to be ignore for now\n",
    "\n",
    "all_accept_df = all_accept_df.drop([\n",
    "    'member_id',\n",
    "    'emp_title',\n",
    "    'emp_length',\n",
    "    'home_ownership',\n",
    "    'url',\n",
    "    'desc',\n",
    "    'title',\n",
    "    'zip_code',\n",
    "    'addr_state',\n",
    "    'initial_list_status',\n",
    "    'verification_status_joint',  \n",
    "    'hardship_type',\n",
    "    'hardship_reason',\n",
    "    'disbursement_method'\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert column to numeric\n",
    "\n",
    "all_accept_df['term'] = pd.to_numeric(all_accept_df['term'].apply(lambda x: re.findall(r'\\d+', str(x))).str[0])\n",
    "all_accept_df['deferral_term'] = pd.to_numeric(all_accept_df['deferral_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummify\n",
    "\n",
    "colsToBeDummified = pd.Series(\n",
    "    ['grade',\n",
    "    'sub_grade',\n",
    "    'verification_status',\n",
    "    'purpose',\n",
    "    'pymnt_plan',\n",
    "    'application_type',\n",
    "    'hardship_flag',\n",
    "    'hardship_status',\n",
    "    'hardship_loan_status',\n",
    "    'debt_settlement_flag',\n",
    "    'settlement_status'])\n",
    "\n",
    "for col in colsToBeDummified:    \n",
    "    all_accept_df = all_accept_df.join(pd.get_dummies(all_accept_df[col], drop_first=True, prefix=col))\n",
    "    all_accept_df = all_accept_df.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handle na\n",
    "\n",
    "all_accept_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1965492\n",
       "0    1965492\n",
       "Name: loan_status, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "df_majority = all_accept_df[all_accept_df['loan_status'] == 1]\n",
    "df_minority = all_accept_df[all_accept_df['loan_status'] == 0]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     \n",
    "                                 n_samples=df_majority.shape[0], \n",
    "                                 random_state=random_state)\n",
    "\n",
    "all_accept_df = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "all_accept_df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "all_accept_train_df, all_accept_test_df, all_accept_train_target, all_accept_test_target = \\\n",
    "            train_test_split(all_accept_df, all_accept_df['loan_status'], test_size=0.2, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-9b912882cf0c>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_accept_train_df[col] = pd.to_numeric(all_accept_train_df[col])\n",
      "<ipython-input-15-9b912882cf0c>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_accept_test_df[col] = pd.to_numeric(all_accept_test_df[col])\n"
     ]
    }
   ],
   "source": [
    "# make sure all columns are numeric\n",
    "\n",
    "for col in all_accept_train_df.columns:\n",
    "    all_accept_train_df[col] = pd.to_numeric(all_accept_train_df[col])\n",
    "    all_accept_test_df[col] = pd.to_numeric(all_accept_test_df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3144787 entries, 142817 to 2152783\n",
      "Columns: 193 entries, id to settlement_status_COMPLETE\n",
      "dtypes: float64(112), int64(14), uint8(67)\n",
      "memory usage: 3.2 GB\n"
     ]
    }
   ],
   "source": [
    "all_accept_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 786197 entries, 18800 to 435839\n",
      "Columns: 193 entries, id to settlement_status_COMPLETE\n",
      "dtypes: float64(112), int64(14), uint8(67)\n",
      "memory usage: 812.0 MB\n"
     ]
    }
   ],
   "source": [
    "all_accept_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_ids = pd.concat([all_accept_train_df['id'], all_accept_test_df['id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## - Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term', 'installment',\n",
    "    'int_rate', 'grade_B', 'grade_C',\n",
    "    'grade_D', 'grade_E', 'grade_F', 'grade_G',\n",
    "    'sub_grade_A2', 'sub_grade_A3', 'sub_grade_A4', 'sub_grade_A5', \n",
    "    'sub_grade_B2', 'sub_grade_B3', 'sub_grade_B4', 'sub_grade_B5',\n",
    "    'sub_grade_C1', 'sub_grade_C2', 'sub_grade_C3', 'sub_grade_C4',\n",
    "    'sub_grade_C5', 'sub_grade_D1', 'sub_grade_D2', 'sub_grade_D3',\n",
    "    'sub_grade_D4', 'sub_grade_D5', 'sub_grade_E1', 'sub_grade_E2',\n",
    "    'sub_grade_E3', 'sub_grade_E4', 'sub_grade_E5', 'sub_grade_F1',\n",
    "    'sub_grade_F2', 'sub_grade_F3', 'sub_grade_F4', 'sub_grade_F5',\n",
    "    'sub_grade_G1', 'sub_grade_G2', 'sub_grade_G3', 'sub_grade_G4',\n",
    "    'sub_grade_G5', 'sub_grade_B1','purpose_credit_card', 'purpose_debt_consolidation',\n",
    "    'purpose_home_improvement', 'purpose_medical', 'purpose_other', \n",
    "    'purpose_small_business', 'annual_inc', 'dti',\n",
    "    'delinq_2yrs', 'fico_range_low', 'fico_range_high',\n",
    "    'open_acc', 'total_acc', 'annual_inc_joint', 'dti_joint',\n",
    "    'inq_last_6mths', 'pub_rec', 'revol_bal', 'revol_util',\n",
    "    'revol_bal_joint', 'sec_app_fico_range_low', 'sec_app_fico_range_high'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = all_accept_train_df.columns.isin(features)\n",
    "\n",
    "kBestColumns = all_accept_train_df.columns[mask]\n",
    "\n",
    "len(kBestColumns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3144787, 68)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accept_train_df = all_accept_train_df[kBestColumns]\n",
    "all_accept_train_df = pd.DataFrame(scaler.fit_transform(all_accept_train_df), columns=features)\n",
    "all_accept_train_df.fillna(0, inplace=True)\n",
    "\n",
    "all_accept_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(786197, 68)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_accept_test_df = all_accept_test_df[kBestColumns]\n",
    "all_accept_test_df = pd.DataFrame(scaler.fit_transform(all_accept_test_df), columns=features)\n",
    "all_accept_test_df.fillna(0, inplace=True)\n",
    "\n",
    "all_accept_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shrink data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_range_train = range(1, all_accept_train_df.shape[0])\n",
    "#n_range_train = range(1, 200000)\n",
    "\n",
    "all_accept_train_df_r = pd.DataFrame(all_accept_train_df.iloc[n_range_train])\n",
    "all_accept_train_target_r = all_accept_train_target.iloc[n_range_train] \n",
    "\n",
    "all_accept_train_df_r.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_range_test = range(1, all_accept_test_df.shape[0])\n",
    "#n_range_test = range(1, 20000)\n",
    "\n",
    "all_accept_test_df_r = pd.DataFrame(all_accept_test_df.iloc[n_range_test])\n",
    "all_accept_test_target_r = all_accept_test_target.iloc[n_range_test] \n",
    "\n",
    "all_accept_test_df_r.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "xgb_c = xgb.XGBClassifier(\n",
    "    objective= 'binary:logistic',\n",
    "    nthread=n_jobs,\n",
    "    seed=random_state,\n",
    "    scale_pos_weight=0.149\n",
    ")\n",
    "\n",
    "parameters = {\n",
    "    'max_depth': [7, 10, 12, 15],\n",
    "    'n_estimators': [200, 300, 400, 500],\n",
    "    'learning_rate': [0.25, 0.2, 0.1, 0.01]\n",
    "}\n",
    "\n",
    "grid_search_xgb = model_selection.GridSearchCV(\n",
    "    estimator=xgb_c,\n",
    "    param_grid=parameters,\n",
    "    scoring = accuracy,\n",
    "    n_jobs = n_jobs,\n",
    "    cv = cv\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%time grid_search_xgb.fit(all_accept_train_df_r, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb.score(all_accept_train_df_r, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(grid_search_xgb.predict(all_accept_train_df_r), all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grid_search_xgb.score(all_accept_test_df_r, all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(grid_search_xgb.predict(all_accept_test_df_r), all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(grid_search_xgb.predict(all_accept_train_df_r), all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(grid_search_xgb.predict(all_accept_test_df_r), all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_xgb.best_estimator_.save_model('xgb_best_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_xgb_df = pd.concat([all_accept_train_df, all_accept_test_df])\n",
    "\n",
    "probablities = grid_search_xgb.predict(all_accept_xgb_df)\n",
    "\n",
    "all_accept_xgb_df = pd.DataFrame(np.column_stack((all_accept_ids, probablities)), columns=['id', 'predicted_val'])\n",
    "all_accept_xgb_df.to_csv('all_accept_xgb_df.csv', index=False)                                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accept_xgb_df.predicted_val.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "\n",
    "import sklearn\n",
    "import time\n",
    "import scipy\n",
    "\n",
    "from tensorflow.python.keras.layers import Dense\n",
    "from tensorflow.python.keras import initializers\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "all_accept_train_df_r_scaled = all_accept_train_df_r #scaler.fit_transform(all_accept_train_df_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed:  62426.27232670784\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tf.set_random_seed(random_state)\n",
    "\n",
    "num_observations = all_accept_train_df_r_scaled.shape[0]\n",
    "num_features     = all_accept_train_df_r_scaled.shape[1]\n",
    "\n",
    "kernel_initializer = initializers.TruncatedNormal(mean=0.0,stddev=0.1)\n",
    "bias_initializer   = initializers.Constant(0.1)\n",
    "    \n",
    "model.add(Dense(num_features*2, input_dim=num_features, input_shape=(num_features,),\n",
    "                activation=tf.nn.relu, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(num_features, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Dense(num_features/2, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=1, activation=tf.nn.sigmoid))\n",
    "\n",
    "bce = tf.keras.losses.BinaryCrossentropy()\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1)\n",
    "\n",
    "model.compile(loss=bce, optimizer=sgd, metrics=[accuracy])\n",
    "\n",
    "model.fit(all_accept_train_df_r_scaled, all_accept_train_target_r.values, epochs=1000, batch_size=100, verbose=0)\n",
    "\n",
    "print('Time elapsed: ', time.time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy:  0.6746026597676281\n",
      "ROC AUC Score:  0.674908664931631\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1093845,  544576],\n",
       "       [ 478729, 1027636]], dtype=int64)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict = model.predict_classes(all_accept_train_df_r_scaled)\n",
    "\n",
    "print ('Training Accuracy: ', np.mean(predict[:,0] == all_accept_train_target_r.values))\n",
    "print ('ROC AUC Score: ', roc_auc_score(predict[:,0], all_accept_train_target_r.values))\n",
    "\n",
    "confusion_matrix(predict, all_accept_train_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy:  0.6707653053437056\n",
      "ROC AUC Score:  0.6713685106759334\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[275117, 141042],\n",
       "       [117801, 252236]], dtype=int64)"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#scaler = StandardScaler()\n",
    "all_accept_test_df_r_scaled = all_accept_test_df_r # scaler.fit_transform(all_accept_test_df_r)\n",
    "\n",
    "predict = model.predict_classes(all_accept_test_df_r_scaled)\n",
    "print('Test Accuracy: ', np.mean(predict[:,0] == all_accept_test_target_r.values))\n",
    "print ('ROC AUC Score: ', roc_auc_score(predict[:,0], all_accept_test_target_r.values))\n",
    "\n",
    "confusion_matrix(predict, all_accept_test_target_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('keras_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kalyan Manda\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "all_accept_keras_df = pd.concat([all_accept_train_df, all_accept_test_df])\n",
    "\n",
    "all_accept_keras_df = scaler.fit_transform(all_accept_keras_df)\n",
    "\n",
    "probablities = model.predict_classes(all_accept_keras_df)\n",
    "\n",
    "all_accept_keras_df = pd.DataFrame(np.column_stack((all_accept_ids, probablities)), columns=['id', 'predicted_val'])\n",
    "all_accept_keras_df.to_csv('all_accept_keras_df.csv', index=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
